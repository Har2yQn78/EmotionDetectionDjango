{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-5SM8Uk845l",
        "outputId": "c888f269-b0a6-4bbc-f3ba-1b6cbe6f4df5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: neattext in /usr/local/lib/python3.10/dist-packages (0.1.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install neattext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5ieZN4zgt9c",
        "outputId": "5e9f7338-e3f1-41a8-a095-24634eaabf04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import neattext.functions as nfx\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import uniform, randint\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gr4gtdieg_nx"
      },
      "outputs": [],
      "source": [
        "emotion_labels = {0: 'sadness', 1: 'joy', 2: 'love', 3: 'anger', 4: 'fear', 5: 'surprise',\n",
        "                  6: 'neutral', 7: 'disgust', 8: 'shame', 9: 'worry', 10: 'fun',\n",
        "                  11: 'relief', 12: 'hate', 13: 'enthusiasm', 14: 'boredom'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zicW-3Djg_p4"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('AllEmotionDataset.csv')\n",
        "\n",
        "df['Clean_text'] = df['text'].apply(nfx.remove_userhandles)\n",
        "df['Clean_text'] = df['Clean_text'].apply(nfx.remove_stopwords)\n",
        "\n",
        "x = df['Clean_text']\n",
        "y = df['label']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhxNVbZl9Fn9"
      },
      "outputs": [],
      "source": [
        "pipe_rf = Pipeline(steps=[\n",
        "    ('cv', CountVectorizer()),\n",
        "    ('rf', RandomForestClassifier(n_estimators=300))\n",
        "])\n",
        "\n",
        "pipe_rf.fit(x_train, y_train)\n",
        "\n",
        "pipe_rf.score(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "bryo3Hoehud8"
      },
      "outputs": [],
      "source": [
        "pipeline_file = open(\"text_emotion.pkl\", \"wb\")\n",
        "joblib.dump(pipe_rf, pipeline_file)\n",
        "pipeline_file.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}